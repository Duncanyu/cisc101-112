
**Submission Template**:


# Week 6 Group Reflection

## Group Members
- [List all group members’ names]

---

## Set 1: Zero-Shot Prompting

### Task 1.1: Zero-Shot Prompt and Comparison

Transcript link (zero-shot prompt) - https://copilot.microsoft.com/shares/9GKWhsrZH7AHP2g5Yu2DH
Transcript link (few-shot prompt) - https://copilot.microsoft.com/shares/UcL6sW9NQzpfbwoGSeQ7t

Analysis - When the prompt was zero-shot formatted, meaning no examples were provided, it went into greater detail in terms of budget, activities, and schedule, because, in theory, the AI thought anything was possible with this itinerary. However, when specific examples were provided later on, the output was concise, listing only four lines: cost, restaurant, museum, and park.

---

## Set 2: Self-Consistency

### Task 2.1: Self-Consistency Assumption Analysis

**Transcript Links:**
https://copilot.microsoft.com/shares/URCosj4bxVPFiZj9JJDSn 

https://copilot.microsoft.com/shares/Q5yVviHbTYdnFr8vw59wt

https://copilot.microsoft.com/shares/Gx1mRW5hosnyyEHSdVuzH

**Comparison Notes:**
- **Strengths:** [Concise information, accurate limitation on budgetary demands]
- **Weaknesses:** [Too varied without any specific actions, benefits do not apply to a large variety]
- **Differences:** [Emphasis on each activity differs (Activity itself or surrounding impact done by activity), or very jutted outputs with little correlation between them]

**Selected Itinerary:**
[(https://copilot.microsoft.com/shares/Q5yVviHbTYdnFr8vw59wt)]

**Justification:**
This version is best suited for the client based on the existing requirements for neatness, while accounting for all additional needs by the client

**Analysis (25 words):**
The benefit of self-consistency is that it allows for improving the accuracy of each prompt output not by repeatedly scrutinizing each prompt element, but by allowing the Large Language Model to do most of the heavy lifting.

---

## Set 3: Spec-Based Development

### Task 3.1: Designing Specifications

**Specifications for “Daily Budget Breakdown” Feature:**
- **Inputs:** [List expected user inputs]
- **Outputs:** [List what AI should produce]
- **Constraints:** [Budget limits, accessibility, etc.]

---

### Task 3.2: Writing and Testing a Prompt

**Final Prompt:**
[Insert your full prompt]

**Transcript Link:**
[Insert test run link]

**Evaluation:**
- **Met specifications?** [Yes/No/Partially]
- **Successes:** [List 1–2 strengths]
- **Failures or gaps:** [List 1–2 issues]

**Improvement Plan (25 words):**
[Describe how you’d improve next iteration]

---

## Set 4: AI-Assisted Debugging

### Task 4.1: Debugging with AI Feedback

**Issues Identified in Set 3:**
[List 2–3 issues you noticed in your spec or prompt]

**Debugging Request Sent to AI:**
[Paste or paraphrase what you asked the AI]

**AI’s Main Suggestions:**
[List 3 key pieces of feedback and their rationale]

**Revised Prompt/Spec:**
[Insert updated version after applying fixes]

**Justification:**
[Briefly explain why you chose these fixes]

**Transcript Links:**
- [Debugging session link]
- [Retest session link]

**Reflection (25 words):**
[Write about which feedback was most useful and why]

---

## Group Reflection (100 words)

**Prompt Engineering Reflection:**


[Insert 100-word group reflection here]

```

**Deliverables**: Markdown file (`group#_week6_reflection.md`) with all task outputs, transcript links, and 100-word reflection.
